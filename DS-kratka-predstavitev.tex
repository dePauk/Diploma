\documentclass{beamer}

\usepackage[slovene]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern, amsthm, graphicx, enumerate, amsmath}

\newtheorem{defn}{Definicija}
\newtheorem{trd}{Trditev}

\usetheme{Madrid}
\setbeamertemplate{footline}{%
  \leavevmode%
  \hbox{\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1.125ex,leftskip=.3cm plus1fill,rightskip=.3cm]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.7\paperwidth,ht=2.5ex,dp=1.125ex,leftskip=.3cm,rightskip=.3cm plus1fil]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}}%
  \vskip0pt%
}

\title{Stohastična optimizacija v diskretnem času}
\author{avtor: Darjan Pavšič \\ mentor: izred. prof. dr. Mihael Perman}
\institute[Fakulteta za matematiko in fiziko, Univerza v Ljubljani]


\date[4. december 2019]
{Kratka predstavitev \\ 4. december 2019}



\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\frametitle{Vsebina}

\begin{itemize}
\item{Optimalna kontrola in deterministično dinamično programiranje}\newline
\item{Zgled determinističnega dinamičnega programiranja}\newline
\item{Ideja vpeljave na stohastično dinamično programiranje}
\end{itemize}

\end{frame}

%\begin{frame}
%\frametitle{Deterministični modeli v diskretnem času}
%
%\begin{itemize}
%\item Podano imamo začetno vrednost $x_0$. Izberimo nek vektor $(u_0, u_1, ..., u_{n-1})$.
%\item Iz teh $u_0, u_1, ..., u_{n-1}$ lahko sestavimo nov vektor $(x_0, x_1, .., x_n)$, kjer $x_t$ dobimo rekurzivno iz zveze $x_{t+1} = g(x_t,u_t)$. 
%\item Optimizirali bi radi komplicirano funkcijo več spremenljivk $F$ s tako izbiro $(u_0, u_1, ..., u_T)$, da bo vrednost $F(u_0, u_1, ..., u_T)$ največja.
%\item Če je $F$ oblike:
%\end{itemize}
%\begin{equation}
%\sum_{t=0}^\infty \beta^t f(u_t,x_t), \-\ \-\ \-\ \-\ 0 < \beta < 1
%\end{equation}
%
%\-\ \-\ \-\ \-\ \-\ \-\ se problema lahko lotimo z dinamičnim programiranjem \textit{(Od kje sledi to ?????)}.
%
%
%\end{frame}


\begin{frame}
\frametitle{Optimalna kontrola in dinamično programiranje}

Predpostavke za problem optimalne kontrole: \newline

\begin{itemize} 

\item Imamo diskreten čas, torej $t \in \mathbb{N}_0$. 
\item Ekonomija je skozi čas opisana z dvema spremenljivkama: stanje $x_t$ in kontrolna spremenljivka $u_t$
\item Vemo, kakšno je začetno stanje $x_0$, prav tako je podan razvoj stanja preko funkcije kontrolne spremenljivke: $x_{t+1} = g_t(x_t,u_t)$
\item Imamo množico $m$ vrednosti kontrolne spremenljivke za vsako obdobje $t \in \mathbb{N}_0$, $u_t \in \mathcal{U} \subset \mathbb{R}^m$

\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Optimalna kontrola in dinamično programiranje}

\begin{itemize}
\item Torej se za vsako zaporedje kontrol $u \equiv \{u_0, u_1, \ldots, u_t\} \in \mathcal{U}$ ekonomija lahko giba po velikem številu dopustnih poti $x \equiv \{ x_0, x_1, \ldots, \}$, ki so določene z $x_{t+1} = g_t(x_t,u_t), u_t \in \mathcal{U}$ \newline
\item Če imamo podan kriterij, na podlagi katerega lahko ovrednotimo vse dopustne poti z vrednostjo $U(x_0, x_1, \ldots , u_0, u_1, \ldots)$ in obstaja optimalna kontrola $u^* = \{u_0^*, u_1^*, ...\}$, ki maksimizira $U$, potem obstaja tudi optimalna pot za spremenljivko stanja $x^* \equiv \{x_0, x_1^*,  \ldots \}$.

\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Optimalna kontrola in dinamično programiranje}

Predvsem v zvezi z ekonomskimi in finančnimi problemi imamo še dodatne predpostavke:

\begin{itemize}
\item $x_t$ je običajno vrednost delnice ki se meri ob začetku obdobja, $u_t$ pa pritok novih naložb v dano delnico, ki se meri ob koncu obdobja
\item Lahko optimiziramo glede na končen ali neskončen čas v prihodnosti
\item Funkcija koristnosti je podana kot 
\begin{equation} 
\sum_{t=0}^T \beta^t f(u_t, x_t),
\end{equation}
kjer $0 < \beta < 1, \beta^0 = 1, lim_{t\to\infty} \beta^t = 0$
\item $\beta$ predstavlja časovno diskontiranje oziroma nestrpnost.
\item To in še nekaj ostalih privzetkov nam da t.i. \textit{problem optimalne kontrole}.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Optimalna kontrola in dinamično programiranje}

\begin{defn}[Problem optimalne kontrole]
\textbf{Problem optimalne kontrole (OCP)} je formuliran kot: \newline

Najdi $\{u_t^*,x_t\}_{t=0}^T$ (\textit{najpreprostejši OCP}) oziroma najdi $\{u_t^*,x_t\}_{t=0}^{T-1}$ (\textit{OCP s prostim končnim stanjem}), ki reši

\begin{equation}
\max_{\{u_t\}_{t=0}^T} \sum_{t=0}^T \beta^t f(u_t,x_t),
\end{equation}

kjer $u_t \in \mathcal{U}$ in $x_{t+1} = g(x_t,u_t)$ \newline

za podana $x_0$ in $x_T$ in poljuben $T$.

\end{defn}

Dosegljivi kandidati za optimum bojo vse poti $\{x_t,u_t\}$, ki zadostujejo pogoju $x_{t+1} = g(x_t,u_t)$ ob podanem $x_0$ in kateri koli izbiri $u_t \in \mathcal{U}$ v vsakem obdobju $t=\{0, \ldots, T\}$.

\end{frame}

\begin{frame}
\frametitle{Dinamično programiranje}

Po Bellmanovem načelu dinamičnega programiranja mora imeti optimalna pot lastnost, da morajo biti za katero koli začetno vrednost stanja $x_0$ in vrednost stanja $x_t$ ter kontrole $u_t$ na začetku obdobja $t$, spremenljivke kontrole izbrane optimalno za preostala obdobja, kjer smo vrednost stanja v trenutnem obdobju dobili na podlagi predhodnih optimalnih odločitev.

\end{frame}

\begin{frame}
\frametitle{Dinamično programiranje}

\begin{defn}[Vrednostna funkcija]

\textbf{Vrednostna funkcija} za čas $\tau$ je:

\begin{equation}
V_{T-{\tau}}(x_{\tau}) = \sum_{t=\tau}^T \beta^{t-\tau} f(u_t^*,x_t^*)
\end{equation}

\end{defn}


\begin{trd}
Optimalna rešitev problema optimalne kontrole  $\{u^*,x_t^*\}_{t=0}^T$ zadostuje Hamilton-Jacobijevi enačbi

\begin{equation}
V_{T-t}(x_t) = \max_{u_t} \{f(x_t,u_t) + \beta V_{T-t-1}(x_{t+1})\}
\end{equation}
\end{trd}

\end{frame}

\begin{frame}
\frametitle{Dinamično programiranje}

Maksimizacije se lotimo v dveh korakih.

\begin{itemize}
\item Najprej je potrebno z rekurzijo poiskati zaporedje $\{V_T, \ldots, V_0\}$:

\begin{equation}
V_{t+1}(x) = \max_u \{f(x,u) + \beta V_t(g(x,u))\}
\end{equation} 

\item Na podlagi dobljenega z reševanjem HJB enačbe dobimo optimalno kontrolo.

\end{itemize}

V primeru neskončnega časa, je $V = \lim_{j\to\infty}V_j$ neodvisen od $j$, zato HJB enačba postane:

\begin{equation}
V(x) = \max_u \{f(x,u) + \beta V[g(x,u)]\} = \max_u H(x,u)
\end{equation}

\end{frame}

\begin{frame}
\frametitle{Dinamično programiranje}

Ob določenih predpostavkah lahko optimalno kontrolo dobimo preko stacionarne točke:

\begin{equation}
\frac{\partial H(x,u)}{\partial u} = 0
\end{equation}

Če je $H \in C^2$, dobimo \textit{policy function- prevod ?????}:

\begin{equation}
u^* = h(x),
\end{equation}

ki nam določa optimalno pravilo za spreminjanje optimalne kontrole glede na stanje ekonomije. \newline

\end{frame}

\begin{frame}
\frametitle{Dinamično programiranje}

V primeru, da tako razmerje obstaja, lahko rečemo, da je naš problem rekurziven in HJB enačba postane sledeča:

\begin{equation}
V(x) = f(x,h(x)) + \beta V[g(x,h(x))], 
\end{equation} \newline


od kjer se vrednosti $V(x)$ običajno išče numerično, saj je eksaktno računanje možno le zelo poredkoma.


\end{frame}


%%&&&

%\begin{frame}
%
%V prostoru zaporedij $\{u_t,x_t\}_{t=0}^\infty$, kjer je $u_t \in {\mathbb{R}}^m$ in $x_t \in {\mathbb{R}}$ bi radi izbrali zaporedje $\{{ {u}_{t}^*},{{x}_{t}^*}\}_{t=0}^\infty$, ki maksimizira vsoto:
%
%
%
%\begin{equation}
%\max_{\{u\}} \sum_{t=0}^\infty \beta^t f(u_t,x_t),
%\end{equation}
%
%kjer je $x_0$ dan, naslednike pa dobimo po predpisu $x_{t+1} = g(x_t,u_t)$ za vsak $t$.\newline
%
%Velja še: $ 0 < \beta < 1$
%
%\end{frame}
%
%\begin{frame}
%
%Stacionarne točke \textit{( principle of dynamic programming ?????)} dobimo s pomočjo tako imenovane Hamilton-Jacobi-Bellmanove (HJB) enačbe (\textit{Od kje sledi to}):
%
%\begin{equation}
%V(x_t) = \max_{u_t} \{f(u_t,x_t) + \beta V(g(u_t,x_t))\}, 
%\end{equation}
%
%ki je običajno napisana kar kot
%
%\begin{equation}
%V(x) = \max_{u} \{f(u,x) + \beta V(g(u,x))\}. 
%\end{equation}
%
%Če $u^*$ obstaja, se jo da zapisati v obliki $u^*=h(x)$, kjer $h(x)$ rečemo (\textit{policy function ?????}).
%
%\end{frame}
%
%\begin{frame}
%
%Sedaj lahko $h(x)$ vstavimo v HJB enačbo in dobimo: \textit{functional equation ????})
%
%\begin{equation}
%V(x) = f(h(x),x) + \beta V [g(h(x),x)].
%\end{equation}
%
%V tem primeru HJB enačbo rešimo, če najdemo funkcijo $V(x)$, ki reši zgornjo enačbo. Če lahko določimo $V(x)$ (eksplicitno ali numerično), lahko določimo tudi $u_t^* = h(x_t)$ (\textit{Od kje to sledi ?????}).\newline
%
%Ta $(h(x_t)$ lahko vstavimo v pogoj $x_{t+1} = g(x_t,u_t)$ ob podanem $x_0$ in dobimo $x_{t+1} = g(x_t, h(x_t))$. V tem primeru dobimo optimalno rešitev problema $\{{ {u}_{t}^*},{{x}_{t}^*}\}_{t=0}^\infty$.
%
%
%\end{frame}
%
%\begin{frame}
%
%\textit{Chapter 2: 8-12 če še kaj povzamem}
%
%\end{frame}

\begin{frame}
\frametitle{Primer: The cake eating problem}

\begin{itemize}
\item Imamo torto, katere velikost v času $t$ je označena z $W_t$ in požrešneža, ki bi rad jedel v $T$ obdobjih.
\item $W_0 = \phi$ in $W_T = 0$
\item Požrešnež ima podan psihološki diskontni faktor $0 < \beta < 1$ in logaritemsko funkcijo koristnosti.
\item Želimo ugotoviti, s kakšno strategijo bo jedel torto, da bo dosegel kar se da veliko korist.
\end{itemize}



\end{frame}

\begin{frame}
\frametitle{Primer: The cake eating problem}

Naš cilj je torej najti optimalne poti $C^* = \{C_t^*\}_{t=0}^{T-1}$ in $W^* = \{W_t^*\}_{t=0}^T$, ki rešijo problem: 

\begin{equation}
\max_C \sum_{t=0}^T \beta ^t ln(C_t), 
\end{equation}

kjer imamo določeno odvisnost $W_{t+1} = W_t - C_t$ in pogoja $W_0 = \phi$ in $W_T = 0$. \newline

(v tej notaciji so $u$ od prej označeni s $C$, $x$ pa z $W$).

\end{frame}

\begin{frame}
\frametitle{Primer: The cake eating problem}

Da lahko rešimo ta primer z dinamičnim programiranjem, se poslužimo HJB kot v zadnji trditvi:

\begin{equation}
V_{T-t}(W_t) = \max_{C_t}\{ln(C_t) + \beta V_{T-t-1}(W_{t+1})\}, \-\ \-\ t = 0, 1, \ldots, T-1
\end{equation}

Upoštevati moramo še rekurzivno zvezo za preostanek torte v obdobju $t+1$, ki je enaka $W_{t+1} = W_t - C_t$. \newline


\end{frame}

\begin{frame}
\frametitle{Primer: The cake eating problem}
Optimalno \textit{policy function ???} za količino zaužite torte dobimo iz

\begin{equation}
\frac{\partial}{\partial C_t}(ln(C_t) +  \beta V_{T-t-1}(W_{t+1})) = 0,
\end{equation}

kar nam da

\begin{equation}
C_t^* = C_t(W_{t+1})) =  (\beta V_{T-t-1}' (W_{t+1})) ^{-1}
\end{equation} \newline

HJB postane parcialna diferencialna enačba:

\begin{equation}
V_{T-t}(W_t) = ln(C_t(W_{T+1})) + \beta V_{T-t-1}(W_{t+1}), \-\ \-\ t = 0,1, \ldots, T-1
\end{equation}

\end{frame}

\begin{frame}
\frametitle{Primer: The cake eating problem}
Ko vse skupaj rešimo, v končni fazi dobimo:

\begin{equation}
C_t^* = \left( \frac{1- \beta }{1- \beta^{T-t}} \right) W_t.
\end{equation}

\end{frame}



\begin{frame}
\frametitle{Ideja vpeljave na stohastično dinamično programiranje}

Spremenljivke $x_t$ in $u_t$ postanejo slučajne spremenljivke, iz tega sledi tudi, da so rekurzivna za $x_{t+1}$, koristnostna in ostale funkcije vse take, da za argumente vzamejo slučajne spremenljivke, zato je vse skupaj nekoliko težjeg in zahteva nekaj znanja slučajnih procesov in verjetnosti z mero.

\end{frame}



\end{document}
